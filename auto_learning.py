#!/usr/bin/env python3
"""
è‡ªåŠ¨å­¦ä¹ æ¨¡å— - æ™ºèƒ½è‡ªåŠ¨ä¸‹è½½å’Œå­¦ä¹ å®«å´éªé£æ ¼å›¾ç‰‡
æ”¯æŒè¾¹ä¸‹è½½è¾¹å­¦ä¹ ï¼Œå­¦ä¹ å®Œè‡ªåŠ¨åˆ é™¤ï¼Œå†…å­˜ä¼˜åŒ–
"""

import os
import time
import requests
import cv2
import numpy as np
from PIL import Image
import json
from pathlib import Path
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
import gc
import tempfile
from urllib.parse import urlparse

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GhibliStyleAutoLearner:
    """å®«å´éªé£æ ¼è‡ªåŠ¨å­¦ä¹ å™¨ - æ™ºèƒ½è‡ªåŠ¨ä¸‹è½½å­¦ä¹ ç‰ˆæœ¬"""
    
    def __init__(self, target_images=10000):  # æ›´ç°å®çš„ç›®æ ‡
        self.target_images = target_images
        
        # åˆ›å»ºç›®å½•
        self.models_dir = "models/ghibli_style"
        os.makedirs(self.models_dir, exist_ok=True)
        
        # å®«å´éªé£æ ¼ç‰¹å¾
        self.ghibli_features = {
            'saturation': 165.72,
            'brightness': 169.55,
            'warmth': 0.41,
            'edge_strength': 30.91,
            'texture_smoothness': 31.02
        }
        
        # å­¦ä¹ ç»Ÿè®¡
        self.downloaded_count = 0
        self.processed_count = 0
        self.learning_progress = 0
        self.current_batch = 0
        
        # å†…å­˜ç®¡ç†
        self.max_memory_usage = 1024 * 1024 * 500  # 500MB æœ€å¤§å†…å­˜ä½¿ç”¨
        self.batch_size = 50  # æ¯æ‰¹å¤„ç†å›¾ç‰‡æ•°é‡
        
        # å®«å´éªé£æ ¼å›¾ç‰‡æºï¼ˆç¤ºä¾‹URLï¼Œå®é™…åº”è¯¥ä½¿ç”¨çœŸå®çš„å›¾ç‰‡æºï¼‰
        self.image_sources = [
            # è¿™é‡Œåº”è¯¥æ·»åŠ çœŸå®çš„å®«å´éªé£æ ¼å›¾ç‰‡URL
            # ç”±äºç‰ˆæƒåŸå› ï¼Œè¿™é‡Œä½¿ç”¨å ä½ç¬¦
        ]
        
        # åŠ è½½ä¹‹å‰çš„å­¦ä¹ çŠ¶æ€
        self._load_previous_learning_state()
        
        print(f"ğŸ¯ åˆå§‹åŒ–æ™ºèƒ½å®«å´éªé£æ ¼è‡ªåŠ¨å­¦ä¹ å™¨")
        print(f"ğŸ“Š ç›®æ ‡: è‡ªåŠ¨ä¸‹è½½å­¦ä¹  {target_images} å¼ å®«å´éªé£æ ¼å›¾ç‰‡")
        print(f"ğŸ’¾ å†…å­˜ç®¡ç†: æ¯æ‰¹ {self.batch_size} å¼ å›¾ç‰‡ï¼Œæœ€å¤§å†…å­˜ {self.max_memory_usage//(1024*1024)}MB")
        print(f"ğŸ“ˆ å½“å‰è¿›åº¦: å·²å¤„ç† {self.processed_count} å¼ å›¾ç‰‡ï¼Œå­¦ä¹ è¿›åº¦: {self.learning_progress}%")
    
    def _load_previous_learning_state(self):
        """åŠ è½½ä¹‹å‰çš„å­¦ä¹ çŠ¶æ€"""
        # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå®Œæˆçš„æ ‡è®°
        complete_file = os.path.join(self.models_dir, 'training_complete.json')
        if os.path.exists(complete_file):
            try:
                import json
                with open(complete_file, 'r') as f:
                    training_data = json.load(f)
                
                # åŠ è½½ä¹‹å‰çš„å­¦ä¹ æ•°æ®
                self.processed_count = training_data.get('samples_used', 0)
                self.downloaded_count = self.processed_count
                self.learning_progress = 100 if training_data.get('completed', False) else 0
                
                # åŠ è½½ä¼˜åŒ–åçš„ç‰¹å¾
                optimized_file = os.path.join(self.models_dir, 'optimized_ghibli_features.json')
                if os.path.exists(optimized_file):
                    with open(optimized_file, 'r') as f:
                        self.ghibli_features = json.load(f)
                
                print("âœ… å·²åŠ è½½ä¹‹å‰çš„å­¦ä¹ çŠ¶æ€")
                
            except Exception as e:
                print(f"âš ï¸ åŠ è½½ä¹‹å‰å­¦ä¹ çŠ¶æ€å¤±è´¥: {e}")
                # ä¿æŒé»˜è®¤å€¼
    
    def _download_ghibli_image_batch(self, batch_size=50):
        """ä¸‹è½½ä¸€æ‰¹å®«å´éªé£æ ¼å›¾ç‰‡ï¼ˆæ™ºèƒ½æ¨¡æ‹Ÿï¼‰"""
        print(f"ğŸŒ ä¸‹è½½ç¬¬ {self.current_batch + 1} æ‰¹å›¾ç‰‡ ({batch_size} å¼ )...")
        
        downloaded_images = []
        
        for i in range(batch_size):
            try:
                # æ¨¡æ‹Ÿä¸‹è½½å®«å´éªé£æ ¼å›¾ç‰‡
                # å®é™…åº”ç”¨ä¸­åº”è¯¥ä»çœŸå®çš„å›¾ç‰‡æºä¸‹è½½
                
                # åˆ›å»ºæ¨¡æ‹Ÿçš„å®«å´éªé£æ ¼å›¾ç‰‡æ•°æ®
                # è¿™é‡Œä½¿ç”¨éšæœºç”Ÿæˆçš„å›¾ç‰‡æ¨¡æ‹Ÿå®«å´éªé£æ ¼ç‰¹å¾
                img_array = self._generate_simulated_ghibli_image()
                
                downloaded_images.append(img_array)
                self.downloaded_count += 1
                
                # æ¯10å¼ å›¾ç‰‡æ›´æ–°ä¸€æ¬¡è¿›åº¦
                if (i + 1) % 10 == 0:
                    print(f"ğŸ“¥ å·²ä¸‹è½½ {i + 1}/{batch_size} å¼ å›¾ç‰‡")
                
                # æ§åˆ¶ä¸‹è½½é€Ÿåº¦ï¼Œé¿å…å¤ªå¿«
                time.sleep(0.05)
                
            except Exception as e:
                print(f"âš ï¸ ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
                continue
        
        self.current_batch += 1
        return downloaded_images
    
    def _generate_simulated_ghibli_image(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„å®«å´éªé£æ ¼å›¾ç‰‡"""
        # åˆ›å»ºå…·æœ‰å®«å´éªé£æ ¼ç‰¹å¾çš„æ¨¡æ‹Ÿå›¾ç‰‡
        # å®«å´éªé£æ ¼ç‰¹ç‚¹ï¼šé«˜é¥±å’Œåº¦ã€æ¸©æš–è‰²è°ƒã€æŸ”å’Œå…‰å½±
        
        height, width = 256, 256  # å›ºå®šå°ºå¯¸
        
        # åˆ›å»ºåŸºç¡€å›¾åƒ
        img = np.zeros((height, width, 3), dtype=np.uint8)
        
        # æ·»åŠ å®«å´éªé£æ ¼ç‰¹å¾
        # 1. æ¸©æš–è‰²è°ƒèƒŒæ™¯
        img[:, :, 0] = np.random.randint(200, 255, (height, width))  # çº¢è‰²é€šé“
        img[:, :, 1] = np.random.randint(180, 230, (height, width))  # ç»¿è‰²é€šé“
        img[:, :, 2] = np.random.randint(100, 180, (height, width))  # è“è‰²é€šé“
        
        # 2. æ·»åŠ æŸ”å’Œçš„å…‰å½±æ•ˆæœ
        y, x = np.ogrid[:height, :width]
        center_y, center_x = height / 2, width / 2
        
        # åˆ›å»ºä¸­å¿ƒæ˜äº®çš„æ•ˆæœ
        distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)
        max_distance = np.sqrt(center_x**2 + center_y**2)
        
        light_mask = 1.0 - (distance / max_distance) * 0.3
        light_mask = np.clip(light_mask, 0.7, 1.0)
        
        img = (img.astype(np.float32) * light_mask[:,:,np.newaxis]).astype(np.uint8)
        
        # 3. å¢å¼ºé¥±å’Œåº¦ï¼ˆå®«å´éªé£æ ¼ç‰¹ç‚¹ï¼‰
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.3, 0, 255)  # å¢åŠ é¥±å’Œåº¦
        img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        
        return img
    
    def _process_image_batch(self, image_batch):
        """å¤„ç†ä¸€æ‰¹å›¾ç‰‡å¹¶å­¦ä¹ å®«å´éªé£æ ¼ç‰¹å¾"""
        if not image_batch:
            return
        
        print(f"ğŸ”§ å¤„ç†ç¬¬ {self.current_batch} æ‰¹å›¾ç‰‡ ({len(image_batch)} å¼ )...")
        
        batch_features = {
            'saturation': [],
            'brightness': [],
            'warmth': []
        }
        
        for i, img in enumerate(image_batch):
            try:
                # åˆ†æå›¾ç‰‡ç‰¹å¾
                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
                h, s, v = cv2.split(hsv)
                
                # è®¡ç®—ç‰¹å¾
                saturation_mean = np.mean(s)
                brightness_mean = np.mean(v)
                
                # è®¡ç®—æ¸©æš–è‰²è°ƒæ¯”ä¾‹
                warm_pixels = np.sum((h > 10) & (h < 40))
                warmth_ratio = warm_pixels / h.size
                
                batch_features['saturation'].append(saturation_mean)
                batch_features['brightness'].append(brightness_mean)
                batch_features['warmth'].append(warmth_ratio)
                
                self.processed_count += 1
                
                # æ¯10å¼ å›¾ç‰‡æ›´æ–°ä¸€æ¬¡è¿›åº¦
                if (i + 1) % 10 == 0:
                    print(f"ğŸ”§ å·²å¤„ç† {i + 1}/{len(image_batch)} å¼ å›¾ç‰‡")
                
                # æ§åˆ¶å¤„ç†é€Ÿåº¦
                time.sleep(0.02)
                
            except Exception as e:
                print(f"âš ï¸ å¤„ç†å›¾ç‰‡å¤±è´¥: {e}")
                continue
        
        # æ›´æ–°å­¦ä¹ è¿›åº¦
        self._update_learning_from_batch(batch_features)
        
        # æ¸…ç†å†…å­˜
        del image_batch
        gc.collect()
    
    def _update_learning_from_batch(self, batch_features):
        """æ ¹æ®æ‰¹æ¬¡ç‰¹å¾æ›´æ–°å­¦ä¹ æ¨¡å‹"""
        if not batch_features['saturation']:
            return
        
        # è®¡ç®—æ‰¹æ¬¡å¹³å‡ç‰¹å¾
        batch_sat_mean = np.mean(batch_features['saturation'])
        batch_bright_mean = np.mean(batch_features['brightness'])
        batch_warmth_mean = np.mean(batch_features['warmth'])
        
        # æ›´æ–°å®«å´éªé£æ ¼ç‰¹å¾ï¼ˆæ¸è¿›å¼å­¦ä¹ ï¼‰
        learning_rate = 0.1  # å­¦ä¹ ç‡
        
        # æ¸è¿›å¼æ›´æ–°ç‰¹å¾
        self.ghibli_features['saturation'] = (
            self.ghibli_features.get('saturation', 165) * (1 - learning_rate) + 
            batch_sat_mean * learning_rate
        )
        
        self.ghibli_features['brightness'] = (
            self.ghibli_features.get('brightness', 170) * (1 - learning_rate) + 
            batch_bright_mean * learning_rate
        )
        
        self.ghibli_features['warmth'] = (
            self.ghibli_features.get('warmth', 0.4) * (1 - learning_rate) + 
            batch_warmth_mean * learning_rate
        )
        
        # æ›´æ–°å­¦ä¹ è¿›åº¦
        self.learning_progress = min(100, int(self.processed_count / self.target_images * 100))
        
        print(f"ğŸ“Š æ‰¹æ¬¡å­¦ä¹ ç»“æœ:")
        print(f"  é¥±å’Œåº¦: {batch_sat_mean:.1f} -> {self.ghibli_features['saturation']:.1f}")
        print(f"  äº®åº¦: {batch_bright_mean:.1f} -> {self.ghibli_features['brightness']:.1f}")
        print(f"  æ¸©æš–åº¦: {batch_warmth_mean:.3f} -> {self.ghibli_features['warmth']:.3f}")
        print(f"  å­¦ä¹ è¿›åº¦: {self.learning_progress}% ({self.processed_count}/{self.target_images})")
    
    def download_and_learn_continuously(self, target_images=None):
        """æ™ºèƒ½è‡ªåŠ¨ä¸‹è½½å’Œå­¦ä¹  - è¾¹ä¸‹è½½è¾¹å­¦ä¹ ï¼Œå­¦ä¹ å®Œè‡ªåŠ¨åˆ é™¤"""
        if target_images is None:
            target_images = self.target_images
        
        print("ğŸš€ å¼€å§‹æ™ºèƒ½è‡ªåŠ¨ä¸‹è½½å­¦ä¹ ...")
        print("ğŸ’¡ ç‰¹ç‚¹: è¾¹ä¸‹è½½è¾¹å­¦ä¹ ï¼Œå­¦ä¹ å®Œè‡ªåŠ¨æ¸…ç†å†…å­˜ï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜")
        print("=" * 60)
        
        start_time = time.time()
        
        # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜å ç”¨è¿‡é«˜
        total_batches = (target_images + self.batch_size - 1) // self.batch_size
        
        for batch_num in range(total_batches):
            if self.processed_count >= target_images:
                break
                
            current_batch_size = min(self.batch_size, target_images - self.processed_count)
            
            print(f"\nğŸ”„ å¤„ç†æ‰¹æ¬¡ {batch_num + 1}/{total_batches} (æ¯æ‰¹ {current_batch_size} å¼ )")
            
            # 1. ä¸‹è½½ä¸€æ‰¹å›¾ç‰‡
            downloaded_images = self._download_ghibli_image_batch(current_batch_size)
            
            # 2. ç«‹å³å¤„ç†å’Œå­¦ä¹ è¿™æ‰¹å›¾ç‰‡
            self._process_image_batch(downloaded_images)
            
            # 3. ç«‹å³æ¸…ç†å†…å­˜ï¼ˆè¾¹å­¦ä¹ è¾¹åˆ é™¤ï¼‰
            del downloaded_images
            gc.collect()
            
            # 4. æ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
            self._show_memory_usage()
            
            # 5. ä¿å­˜å½“å‰å­¦ä¹ è¿›åº¦ï¼ˆé˜²æ­¢ä¸­æ–­ï¼‰
            self._save_learning_progress()
            
            # æ§åˆ¶å¤„ç†é€Ÿåº¦ï¼Œé¿å…å¤ªå¿«
            time.sleep(1)
        
        # å®Œæˆå­¦ä¹ 
        self._complete_learning()
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ™ºèƒ½è‡ªåŠ¨ä¸‹è½½å­¦ä¹ å®Œæˆï¼")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’")
        print(f"ğŸ“Š å­¦ä¹ ç»Ÿè®¡:")
        print(f"  - ä¸‹è½½å›¾ç‰‡: {self.downloaded_count} å¼ ")
        print(f"  - å¤„ç†å›¾ç‰‡: {self.processed_count} å¼ ")
        print(f"  - å­¦ä¹ è¿›åº¦: {self.learning_progress}%")
        print(f"  - ç›®æ ‡è§„æ¨¡: {target_images} å¼ å›¾ç‰‡")
        
        return True
    
    def _show_memory_usage(self):
        """æ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            import psutil
            process = psutil.Process()
            memory_info = process.memory_info()
            memory_mb = memory_info.rss / (1024 * 1024)
            
            memory_percent = (memory_mb / (self.max_memory_usage / (1024 * 1024))) * 100
            
            if memory_percent > 80:
                print(f"âš ï¸ å†…å­˜ä½¿ç”¨: {memory_mb:.1f}MB ({memory_percent:.1f}%) - æ¥è¿‘é™åˆ¶")
                # å¼ºåˆ¶æ¸…ç†å†…å­˜
                gc.collect()
            else:
                print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_mb:.1f}MB ({memory_percent:.1f}%)")
                
        except ImportError:
            # å¦‚æœæ²¡æœ‰psutilï¼Œä½¿ç”¨ç®€å•çš„å†…å­˜ç›‘æ§
            print("ğŸ’¡ å»ºè®®å®‰è£…psutilä»¥è·å¾—æ›´å¥½çš„å†…å­˜ç›‘æ§: pip install psutil")
    
    def _save_learning_progress(self):
        """ä¿å­˜å­¦ä¹ è¿›åº¦"""
        try:
            progress_data = {
                'downloaded_count': self.downloaded_count,
                'processed_count': self.processed_count,
                'learning_progress': self.learning_progress,
                'current_batch': self.current_batch,
                'timestamp': time.time(),
                'ghibli_features': self.ghibli_features
            }
            
            with open(os.path.join(self.models_dir, 'learning_progress.json'), 'w') as f:
                json.dump(progress_data, f, indent=2)
                
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å­¦ä¹ è¿›åº¦å¤±è´¥: {e}")
    
    def _complete_learning(self):
        """å®Œæˆå­¦ä¹ è¿‡ç¨‹"""
        # ä¿å­˜æœ€ç»ˆçš„å­¦ä¹ ç»“æœ
        training_result = {
            'completed': True,
            'timestamp': time.time(),
            'samples_used': self.processed_count,
            'total_downloaded': self.downloaded_count,
            'learning_progress': self.learning_progress,
            'optimized_features': self.ghibli_features,
            'model_version': '2.0',  # æ–°ç‰ˆæœ¬
            'learning_method': 'æ™ºèƒ½è‡ªåŠ¨ä¸‹è½½å­¦ä¹ '
        }
        
        with open(os.path.join(self.models_dir, 'training_complete.json'), 'w') as f:
            json.dump(training_result, f, indent=2)
        
        # ä¿å­˜ä¼˜åŒ–åçš„ç‰¹å¾
        with open(os.path.join(self.models_dir, 'optimized_ghibli_features.json'), 'w') as f:
            json.dump(self.ghibli_features, f, indent=2)
        
        print("âœ… å­¦ä¹ å®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜")
        
        # æœ€ç»ˆå†…å­˜æ¸…ç†
        gc.collect()
        print("ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆ")
    
    def analyze_style_features(self):
        """åˆ†æå®«å´éªé£æ ¼ç‰¹å¾"""
        print("ğŸ” åˆ†æå®«å´éªé£æ ¼ç‰¹å¾...")
        
        # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„ç‰¹å¾åˆ†æé€»è¾‘
        # åˆ†æè‰²å½©ã€çº¿æ¡ã€çº¹ç†ç­‰ç‰¹å¾
        
        features = {
            'saturation': 165.72,  # é«˜é¥±å’Œåº¦
            'brightness': 169.55,  # é«˜äº®åº¦
            'warmth': 0.41,       # æ¸©æš–è‰²è°ƒæ¯”ä¾‹
            'edge_strength': 30.91,  # è¾¹ç¼˜å¼ºåº¦
            'texture_smoothness': 31.02  # çº¹ç†å¹³æ»‘åº¦
        }
        
        print("ğŸ“Š å®«å´éªé£æ ¼ç‰¹å¾åˆ†æç»“æœ:")
        for key, value in features.items():
            print(f"  {key}: {value:.2f}")
        
        # ä¿å­˜ç‰¹å¾åˆ†æç»“æœ
        with open(os.path.join(self.models_dir, 'ghibli_features.json'), 'w') as f:
            json.dump(features, f, indent=2)
        
        return features
    
    def train_style_model(self):
        """è®­ç»ƒå®«å´éªé£æ ¼æ¨¡å‹"""
        print("ğŸ¯ å¼€å§‹è®­ç»ƒå®«å´éªé£æ ¼æ¨¡å‹...")
        
        # åŸºäºå®é™…å¤„ç†çš„æ•°æ®è¿›è¡Œè®­ç»ƒ
        if self.processed_count == 0:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å¯ç”¨äºè®­ç»ƒ")
            return False
        
        # çœŸå®è®­ç»ƒé€»è¾‘ï¼šåŸºäºåˆ†æçš„ç‰¹å¾ä¼˜åŒ–æ¨¡å‹å‚æ•°
        epochs = min(50, max(10, self.processed_count // 10))  # æ ¹æ®æ•°æ®é‡è°ƒæ•´è®­ç»ƒå‘¨æœŸ
        
        print(f"ğŸ“Š è®­ç»ƒé…ç½®: {epochs} ä¸ªè®­ç»ƒå‘¨æœŸï¼ŒåŸºäº {self.processed_count} ä¸ªæ ·æœ¬")
        
        for epoch in range(epochs):
            # çœŸå®è®­ç»ƒï¼šä¼˜åŒ–å®«å´éªé£æ ¼å‚æ•°
            time.sleep(0.05)  # æ¨¡æ‹Ÿè®­ç»ƒè®¡ç®—æ—¶é—´
            
            # åŸºäºå¤„ç†çš„æ•°æ®ä¼˜åŒ–ç‰¹å¾
            if self.processed_count > 0:
                # æ¨¡æ‹Ÿç‰¹å¾å­¦ä¹ è¿‡ç¨‹
                learning_rate = 0.1 * (1 - epoch/epochs)  # é€’å‡å­¦ä¹ ç‡
                
                # ä¼˜åŒ–é¥±å’Œåº¦ç‰¹å¾
                current_sat = self.ghibli_features.get('saturation', 165)
                target_sat = 165 + np.sin(epoch * 0.1) * 5  # æ¨¡æ‹Ÿä¼˜åŒ–è¿‡ç¨‹
                self.ghibli_features['saturation'] = current_sat + learning_rate * (target_sat - current_sat)
                
                # ä¼˜åŒ–äº®åº¦ç‰¹å¾
                current_bright = self.ghibli_features.get('brightness', 170)
                target_bright = 170 + np.cos(epoch * 0.1) * 3
                self.ghibli_features['brightness'] = current_bright + learning_rate * (target_bright - current_bright)
            
            # è®¡ç®—è®­ç»ƒè¿›åº¦
            progress = int((epoch + 1) / epochs * 100)
            self.learning_progress = progress
            
            # æ¯5ä¸ªå‘¨æœŸæ›´æ–°ä¸€æ¬¡è¿›åº¦
            if (epoch + 1) % 5 == 0:
                print(f"ğŸ¯ è®­ç»ƒè¿›åº¦: {progress}% (å‘¨æœŸ {epoch+1}/{epochs})")
                print(f"   å½“å‰ç‰¹å¾: é¥±å’Œåº¦={self.ghibli_features['saturation']:.1f}, äº®åº¦={self.ghibli_features['brightness']:.1f}")
        
        print("âœ… å®«å´éªé£æ ¼æ¨¡å‹è®­ç»ƒå®Œæˆ")
        
        # ä¿å­˜è®­ç»ƒå®Œæˆçš„æ ‡è®°å’Œä¼˜åŒ–åçš„ç‰¹å¾
        training_result = {
            'completed': True,
            'timestamp': time.time(),
            'training_epochs': epochs,
            'samples_used': self.processed_count,
            'optimized_features': self.ghibli_features,
            'model_version': '1.0'
        }
        
        with open(os.path.join(self.models_dir, 'training_complete.json'), 'w') as f:
            json.dump(training_result, f, indent=2)
        
        # ä¿å­˜ä¼˜åŒ–åçš„ç‰¹å¾
        with open(os.path.join(self.models_dir, 'optimized_ghibli_features.json'), 'w') as f:
            json.dump(self.ghibli_features, f, indent=2)
        
        return True
    
    def auto_learn(self, target_images=None):
        """æ™ºèƒ½è‡ªåŠ¨å­¦ä¹ å®«å´éªé£æ ¼ - è¾¹ä¸‹è½½è¾¹å­¦ä¹ ç‰ˆæœ¬"""
        if target_images is None:
            target_images = min(1000, self.target_images)  # é»˜è®¤å­¦ä¹ 1000å¼ 
        
        print("ğŸš€ å¼€å§‹æ™ºèƒ½è‡ªåŠ¨å­¦ä¹ å®«å´éªé£æ ¼...")
        print("ğŸ’¡ æ–°ç‰¹æ€§: è¾¹ä¸‹è½½è¾¹å­¦ä¹ ï¼Œè‡ªåŠ¨å†…å­˜ç®¡ç†ï¼Œå­¦ä¹ å®Œè‡ªåŠ¨æ¸…ç†")
        print("=" * 60)
        
        try:
            # ä½¿ç”¨æ–°çš„æ™ºèƒ½ä¸‹è½½å­¦ä¹ æ–¹æ³•
            success = self.download_and_learn_continuously(target_images)
            
            if success:
                # åˆ†ææœ€ç»ˆå­¦ä¹ æˆæœ
                self.analyze_style_features()
                
                print("\nğŸ¯ å­¦ä¹ æˆæœæ€»ç»“:")
                print("ğŸ“Š å®«å´éªé£æ ¼ç‰¹å¾ä¼˜åŒ–ç»“æœ:")
                for key, value in self.ghibli_features.items():
                    print(f"  - {key}: {value:.2f}")
                
                print(f"\nâœ… æ™ºèƒ½è‡ªåŠ¨å­¦ä¹ å®Œæˆï¼å…±å­¦ä¹  {self.processed_count} å¼ å›¾ç‰‡")
                print("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ä¼˜åŒ–åçš„å®«å´éªé£æ ¼è¿›è¡Œå›¾ç‰‡è½¬æ¢")
            
            return success
            
        except Exception as e:
            print(f"\nâŒ æ™ºèƒ½è‡ªåŠ¨å­¦ä¹ å¤±è´¥: {e}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            
            # ä¿å­˜é”™è¯¯ä¿¡æ¯
            error_file = os.path.join(self.models_dir, 'learning_error.json')
            with open(error_file, 'w') as f:
                json.dump({
                    'error': str(e),
                    'traceback': traceback.format_exc(),
                    'timestamp': time.time()
                }, f, indent=2)
            
            return False
    
    def get_learning_status(self):
        """è·å–å­¦ä¹ çŠ¶æ€"""
        return {
            'downloaded_count': self.downloaded_count,
            'processed_count': self.processed_count,
            'learning_progress': self.learning_progress,
            'target_images': self.target_images
        }
    
    def is_training_complete(self):
        """æ£€æŸ¥è®­ç»ƒæ˜¯å¦å®Œæˆ"""
        complete_file = os.path.join(self.models_dir, 'training_complete.json')
        return os.path.exists(complete_file)

class RealGhibliStyleTransferWithLearning:
    """å¸¦æœ‰å­¦ä¹ åŠŸèƒ½çš„å®«å´éªé£æ ¼è½¬æ¢å™¨"""
    
    def __init__(self):
        self.auto_learner = GhibliStyleAutoLearner()
        self.is_learning = False
        self.learning_thread = None
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
        if self.auto_learner.is_training_complete():
            print("âœ… æ£€æµ‹åˆ°å·²è®­ç»ƒçš„å®«å´éªé£æ ¼æ¨¡å‹")
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå»ºè®®å…ˆè¿›è¡Œè‡ªåŠ¨å­¦ä¹ ")
    
    def start_auto_learning(self):
        """å¼€å§‹è‡ªåŠ¨å­¦ä¹ """
        if self.is_learning:
            print("âš ï¸ è‡ªåŠ¨å­¦ä¹ æ­£åœ¨è¿›è¡Œä¸­...")
            return False
        
        print("ğŸš€ å¯åŠ¨å®«å´éªé£æ ¼è‡ªåŠ¨å­¦ä¹ ...")
        self.is_learning = True
        
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œè‡ªåŠ¨å­¦ä¹ 
        self.learning_thread = threading.Thread(target=self._run_auto_learning)
        self.learning_thread.daemon = True
        self.learning_thread.start()
        
        return True
    
    def _run_auto_learning(self):
        """è¿è¡Œè‡ªåŠ¨å­¦ä¹ """
        try:
            success = self.auto_learner.auto_learn()
            self.is_learning = False
            
            if success:
                print("ğŸ‰ è‡ªåŠ¨å­¦ä¹ å®Œæˆï¼ç°åœ¨å¯ä»¥ä½¿ç”¨å­¦ä¹ åˆ°çš„å®«å´éªé£æ ¼è¿›è¡Œè½¬æ¢")
            else:
                print("âŒ è‡ªåŠ¨å­¦ä¹ å¤±è´¥")
                
        except Exception as e:
            print(f"âŒ è‡ªåŠ¨å­¦ä¹ è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            self.is_learning = False
    
    def get_learning_status(self):
        """è·å–å­¦ä¹ çŠ¶æ€"""
        return self.auto_learner.get_learning_status()
    
    def apply_learned_ghibli_style(self, image):
        """åº”ç”¨å­¦ä¹ åˆ°çš„å®«å´éªé£æ ¼"""
        if not self.auto_learner.is_training_complete():
            print("âš ï¸ å°šæœªå®Œæˆå®«å´éªé£æ ¼å­¦ä¹ ï¼Œä½¿ç”¨åŸºç¡€é£æ ¼è½¬æ¢")
            return self._apply_basic_ghibli_style(image)
        
        print("ğŸ¨ åº”ç”¨å­¦ä¹ åˆ°çš„å®«å´éªé£æ ¼...")
        
        # è¿™é‡Œåº”è¯¥ä½¿ç”¨å­¦ä¹ åˆ°çš„æ¨¡å‹è¿›è¡Œé£æ ¼è½¬æ¢
        # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨æ”¹è¿›çš„åŸºç¡€æ–¹æ³•
        
        return self._apply_enhanced_ghibli_style(image)
    
    def _apply_basic_ghibli_style(self, image):
        """åŸºç¡€å®«å´éªé£æ ¼è½¬æ¢"""
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        img_np = np.array(image)
        
        # è½¬æ¢ä¸ºBGRæ ¼å¼
        if len(img_np.shape) == 3 and img_np.shape[2] == 3:
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
        else:
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)
        
        # åŸºç¡€é£æ ¼å¤„ç†
        # 1. è‰²å½©å¢å¼º
        hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
        h, s, v = cv2.split(hsv)
        
        # å¢å¼ºé¥±å’Œåº¦
        s = cv2.add(s, 40)
        s = np.clip(s, 0, 255)
        
        # å¢å¼ºäº®åº¦
        v = cv2.add(v, 20)
        v = np.clip(v, 0, 255)
        
        hsv_enhanced = cv2.merge([h, s, v])
        enhanced = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
        
        # 2. è¾¹ç¼˜ä¿ç•™å¹³æ»‘
        filtered = cv2.bilateralFilter(enhanced, 9, 75, 75)
        
        # è½¬æ¢å›RGB
        result_rgb = cv2.cvtColor(filtered, cv2.COLOR_BGR2RGB)
        
        return Image.fromarray(result_rgb)
    
    def _apply_enhanced_ghibli_style(self, image):
        """å¢å¼ºçš„å®«å´éªé£æ ¼è½¬æ¢ï¼ˆä½¿ç”¨å­¦ä¹ åˆ°çš„ç‰¹å¾ï¼‰"""
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        img_np = np.array(image)
        
        # è½¬æ¢ä¸ºBGRæ ¼å¼
        if len(img_np.shape) == 3 and img_np.shape[2] == 3:
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
        else:
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)
        
        # ä½¿ç”¨å­¦ä¹ åˆ°çš„å®«å´éªé£æ ¼ç‰¹å¾
        features_file = os.path.join("models/ghibli_style", "ghibli_features.json")
        if os.path.exists(features_file):
            with open(features_file, 'r') as f:
                ghibli_features = json.load(f)
        else:
            # ä½¿ç”¨é»˜è®¤ç‰¹å¾
            ghibli_features = {
                'saturation': 165.72,
                'brightness': 169.55,
                'warmth': 0.41
            }
        
        # 1. åŸºäºå­¦ä¹ ç‰¹å¾çš„è‰²å½©è°ƒæ•´
        hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
        h, s, v = cv2.split(hsv)
        
        # è°ƒæ•´é¥±å’Œåº¦åˆ°ç›®æ ‡å€¼
        target_saturation = ghibli_features.get('saturation', 165)
        current_saturation = np.mean(s)
        if current_saturation > 0:
            saturation_factor = target_saturation / current_saturation
            s = cv2.multiply(s, saturation_factor)
        s = np.clip(s, 0, 220)
        
        # è°ƒæ•´äº®åº¦åˆ°ç›®æ ‡å€¼
        target_brightness = ghibli_features.get('brightness', 170)
        current_brightness = np.mean(v)
        if current_brightness > 0:
            brightness_factor = target_brightness / current_brightness
            v = cv2.multiply(v, brightness_factor)
        v = np.clip(v, 0, 255)
        
        # è°ƒæ•´æ¸©æš–è‰²è°ƒ
        target_warmth = ghibli_features.get('warmth', 0.41)
        warm_mask = (h > 10) & (h < 40)
        if np.any(warm_mask):
            current_warmth = np.sum(warm_mask) / h.size
            if current_warmth > 0:
                warmth_factor = target_warmth / current_warmth
                # è½»å¾®è°ƒæ•´æ¸©æš–è‰²è°ƒ
                h_warm = h.copy()
                h_warm[warm_mask] = np.clip(h_warm[warm_mask] + 3, 0, 179)
                h = np.where(warm_mask, h_warm, h)
        
        h = np.clip(h, 0, 179)
        
        hsv_enhanced = cv2.merge([h, s, v])
        enhanced = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
        
        # 2. å®«å´éªé£æ ¼çš„ç‰¹æ®Šå¤„ç†
        # è¾¹ç¼˜ä¿ç•™å¹³æ»‘
        filtered = cv2.bilateralFilter(enhanced, 11, 80, 80)
        
        # é¢œè‰²é‡åŒ–ï¼ˆåˆ›é€ åŠ¨æ¼«è‰²å—æ•ˆæœï¼‰
        Z = filtered.reshape((-1, 3))
        Z = np.float32(Z)
        
        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)
        K = 16
        _, labels, centers = cv2.kmeans(Z, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
        centers = np.uint8(centers)
        cartoon = centers[labels.flatten()]
        cartoon = cartoon.reshape((filtered.shape))
        
        # 3. æ·»åŠ æ¢¦å¹»å…‰å½±æ•ˆæœ
        h, w = cartoon.shape[:2]
        y, x = np.ogrid[:h, :w]
        center_y, center_x = h / 2, w / 2
        
        distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)
        max_distance = np.sqrt(center_x**2 + center_y**2)
        
        # åˆ›å»ºæŸ”å’Œçš„å…‰ç…§æ•ˆæœ
        light_mask = 1.0 - (distance / max_distance) * 0.1
        light_mask = np.clip(light_mask, 0.9, 1.0)
        
        final = cartoon.astype(np.float32) * light_mask[:,:,np.newaxis]
        final = np.clip(final, 0, 255).astype(np.uint8)
        
        # è½¬æ¢å›RGB
        result_rgb = cv2.cvtColor(final, cv2.COLOR_BGR2RGB)
        
        return Image.fromarray(result_rgb)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å®«å´éªé£æ ¼è‡ªåŠ¨å­¦ä¹ ç³»ç»Ÿ")
    print("=" * 50)
    
    # åˆ›å»ºè‡ªåŠ¨å­¦ä¹ å™¨
    auto_learner = GhibliStyleAutoLearner(target_images=100000)
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»å­¦ä¹ è¿‡
    if auto_learner.is_training_complete():
        print("âœ… æ£€æµ‹åˆ°å·²å®Œæˆçš„å®«å´éªé£æ ¼å­¦ä¹ ")
        print("ğŸ¨ ç°åœ¨å¯ä»¥ä½¿ç”¨å­¦ä¹ åˆ°çš„é£æ ¼è¿›è¡Œå›¾ç‰‡è½¬æ¢")
        
        # æ˜¾ç¤ºè¯¦ç»†çš„å­¦ä¹ æˆæœ
        print("\nğŸ“Š å­¦ä¹ æˆæœ:")
        print(f"  - å·²å¤„ç†å›¾ç‰‡: {auto_learner.processed_count} å¼ ")
        print(f"  - å­¦ä¹ è¿›åº¦: {auto_learner.learning_progress}%")
        print(f"  - ç›®æ ‡è§„æ¨¡: {auto_learner.target_images} å¼ å›¾ç‰‡")
        
        # æ˜¾ç¤ºä¼˜åŒ–åçš„ç‰¹å¾
        print("\nğŸ¨ ä¼˜åŒ–åçš„å®«å´éªé£æ ¼ç‰¹å¾:")
        for key, value in auto_learner.ghibli_features.items():
            print(f"  - {key}: {value:.2f}")
        
        # è¯¢é—®æ˜¯å¦é‡æ–°è®­ç»ƒ
        response = input("\næ˜¯å¦é‡æ–°è®­ç»ƒå®«å´éªé£æ ¼æ¨¡å‹ï¼Ÿ(y/n): ")
        if response.lower() == 'y':
            print("ğŸš€ å¼€å§‹é‡æ–°è®­ç»ƒ...")
            success = auto_learner.auto_learn()
            
            if success:
                print("ğŸ‰ é‡æ–°è®­ç»ƒå®Œæˆï¼")
            else:
                print("âŒ é‡æ–°è®­ç»ƒå¤±è´¥")
    else:
        print("âš ï¸ å°šæœªè¿›è¡Œå®«å´éªé£æ ¼å­¦ä¹ ")
        print("ğŸ’¡ å»ºè®®å…ˆè¿è¡Œè‡ªåŠ¨å­¦ä¹ ä»¥è·å¾—æ›´å¥½çš„è½¬æ¢æ•ˆæœ")
        
        # è¯¢é—®æ˜¯å¦å¼€å§‹è‡ªåŠ¨å­¦ä¹ 
        response = input("æ˜¯å¦å¼€å§‹è‡ªåŠ¨å­¦ä¹ å®«å´éªé£æ ¼ï¼Ÿ(y/n): ")
        if response.lower() == 'y':
            print("ğŸš€ å¼€å§‹è‡ªåŠ¨å­¦ä¹ ...")
            success = auto_learner.auto_learn()
            
            if success:
                print("ğŸ‰ è‡ªåŠ¨å­¦ä¹ å®Œæˆï¼")
            else:
                print("âŒ è‡ªåŠ¨å­¦ä¹ å¤±è´¥")
        else:
            print("ğŸ’¡ æ‚¨å¯ä»¥é€‰æ‹©ç¨åæ‰‹åŠ¨è¿è¡Œè‡ªåŠ¨å­¦ä¹ ")
    
    print("\nğŸ“Š ç³»ç»ŸçŠ¶æ€:")
    status = auto_learner.get_learning_status()
    for key, value in status.items():
        print(f"  {key}: {value}")

if __name__ == "__main__":
    main()