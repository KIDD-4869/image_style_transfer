#!/usr/bin/env python3
"""
å®«å´éªé£æ ¼ä¼˜åŒ–å™¨ - åŸºäºçœŸå®å®«å´éªå›¾ç‰‡è®­ç»ƒå’Œæ”¹è¿›æ¨¡å‹
"""

import cv2
import numpy as np
from PIL import Image
import os
import glob
import json
from collections import defaultdict
import matplotlib.pyplot as plt

class GhibliStyleOptimizer:
    """å®«å´éªé£æ ¼ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.reference_folder = 'temp'
        self.analysis_results = {}
        
    def collect_ghibli_references(self):
        """æ”¶é›†å®«å´éªå‚è€ƒå›¾ç‰‡å¹¶åˆ†æç‰¹å¾"""
        print("ğŸ” æ”¶é›†å’Œåˆ†æå®«å´éªé£æ ¼å‚è€ƒå›¾ç‰‡...")
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.webp']
        reference_images = []
        
        for ext in image_extensions:
            pattern = os.path.join(self.reference_folder, ext)
            reference_images.extend(glob.glob(pattern))
        
        if not reference_images:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å®«å´éªå‚è€ƒå›¾ç‰‡ï¼Œè¯·å°†å›¾ç‰‡æ”¾å…¥tempæ–‡ä»¶å¤¹")
            return False
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(reference_images)} å¼ å‚è€ƒå›¾ç‰‡")
        
        # åˆ†ææ¯å¼ å›¾ç‰‡çš„ç‰¹å¾
        self.analysis_results = self._analyze_ghibli_features(reference_images)
        
        # ä¿å­˜åˆ†æç»“æœ
        self._save_analysis_results()
        
        return True
    
    def _analyze_ghibli_features(self, image_paths):
        """åˆ†æå®«å´éªé£æ ¼ç‰¹å¾"""
        analysis = {
            'color_analysis': defaultdict(list),
            'texture_analysis': defaultdict(list),
            'character_analysis': defaultdict(list),
            'lighting_analysis': defaultdict(list),
            'composition_analysis': defaultdict(list)
        }
        
        for img_path in image_paths:
            try:
                img = cv2.imread(img_path)
                if img is None:
                    continue
                
                print(f"ğŸ“– åˆ†æ: {os.path.basename(img_path)}")
                
                # è‰²å½©åˆ†æ
                color_features = self._analyze_colors(img)
                for key, value in color_features.items():
                    analysis['color_analysis'][key].append(value)
                
                # çº¹ç†åˆ†æ
                texture_features = self._analyze_textures(img)
                for key, value in texture_features.items():
                    analysis['texture_analysis'][key].append(value)
                
                # äººç‰©åˆ†æï¼ˆé‡ç‚¹ï¼‰
                character_features = self._analyze_characters(img)
                for key, value in character_features.items():
                    analysis['character_analysis'][key].append(value)
                
                # å…‰å½±åˆ†æ
                lighting_features = self._analyze_lighting(img)
                for key, value in lighting_features.items():
                    analysis['lighting_analysis'][key].append(value)
                
                # æ„å›¾åˆ†æ
                composition_features = self._analyze_composition(img)
                for key, value in composition_features.items():
                    analysis['composition_analysis'][key].append(value)
                    
            except Exception as e:
                print(f"âŒ åˆ†æ {img_path} æ—¶å‡ºé”™: {e}")
        
        return analysis
    
    def _analyze_colors(self, img):
        """åˆ†æè‰²å½©ç‰¹å¾"""
        # è½¬æ¢ä¸ºHSVè‰²å½©ç©ºé—´
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # åˆ†æè‰²è°ƒåˆ†å¸ƒ
        hue_hist = cv2.calcHist([hsv], [0], None, [180], [0, 180])
        
        # åˆ†æé¥±å’Œåº¦å’Œäº®åº¦
        saturation = np.mean(hsv[:,:,1])
        brightness = np.mean(hsv[:,:,2])
        
        # æå–ä¸»è‰²è°ƒ
        pixels = img.reshape(-1, 3)
        dominant_colors = self._extract_dominant_colors(pixels, 5)
        
        return {
            'hue_distribution': hue_hist.flatten().tolist(),
            'saturation': float(saturation),
            'brightness': float(brightness),
            'dominant_colors': dominant_colors
        }
    
    def _analyze_textures(self, img):
        """åˆ†æçº¹ç†ç‰¹å¾"""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # è®¡ç®—çº¹ç†ç‰¹å¾
        # ä½¿ç”¨å±€éƒ¨äºŒå€¼æ¨¡å¼(LBP)åˆ†æçº¹ç†
        lbp = self._compute_lbp(gray)
        
        # è®¡ç®—æ¢¯åº¦ç‰¹å¾
        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        
        return {
            'texture_variance': float(np.var(gray)),
            'gradient_strength': float(np.mean(gradient_magnitude))
        }
    
    def _analyze_characters(self, img):
        """åˆ†æäººç‰©ç‰¹å¾ï¼ˆé‡ç‚¹ä¼˜åŒ–åŒºåŸŸï¼‰"""
        # ä½¿ç”¨äººè„¸æ£€æµ‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        face_features = self._detect_faces(img)
        
        # åˆ†æçš®è‚¤åŒºåŸŸ
        skin_features = self._analyze_skin_regions(img)
        
        # åˆ†æå¤´å‘åŒºåŸŸ
        hair_features = self._analyze_hair_regions(img)
        
        return {
            'face_detected': len(face_features) > 0,
            'skin_tone': skin_features.get('average_skin_tone', [0, 0, 0]),
            'hair_color': hair_features.get('average_hair_color', [0, 0, 0]),
            'character_sharpness': float(self._calculate_sharpness(img))
        }
    
    def _analyze_lighting(self, img):
        """åˆ†æå…‰å½±ç‰¹å¾"""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # åˆ†æå…‰ç…§åˆ†å¸ƒ
        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        
        # è®¡ç®—å¯¹æ¯”åº¦
        contrast = np.std(gray)
        
        # åˆ†æé˜´å½±å’Œé«˜å…‰åŒºåŸŸ
        shadow_threshold = 50
        highlight_threshold = 200
        
        shadow_pixels = np.sum(gray < shadow_threshold)
        highlight_pixels = np.sum(gray > highlight_threshold)
        total_pixels = gray.size
        
        return {
            'contrast': float(contrast),
            'shadow_ratio': float(shadow_pixels / total_pixels),
            'highlight_ratio': float(highlight_pixels / total_pixels)
        }
    
    def _analyze_composition(self, img):
        """åˆ†ææ„å›¾ç‰¹å¾"""
        h, w = img.shape[:2]
        
        # åˆ†æå›¾åƒä¸­å¿ƒåŒºåŸŸ
        center_region = img[h//4:3*h//4, w//4:3*w//4]
        center_brightness = np.mean(cv2.cvtColor(center_region, cv2.COLOR_BGR2GRAY))
        
        return {
            'aspect_ratio': float(w / h),
            'center_brightness': float(center_brightness)
        }
    
    def _extract_dominant_colors(self, pixels, n_colors):
        """æå–ä¸»è‰²è°ƒ"""
        # ä½¿ç”¨K-meansèšç±»æå–ä¸»è‰²è°ƒ
        pixels_float = np.float32(pixels)
        
        # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥è®¡ç®—å¹³å‡é¢œè‰²
        if len(pixels) > 0:
            avg_color = np.mean(pixels, axis=0)
            return [avg_color.tolist()]
        
        return [[0, 0, 0]]
    
    def _compute_lbp(self, gray):
        """è®¡ç®—å±€éƒ¨äºŒå€¼æ¨¡å¼"""
        # ç®€åŒ–çš„LBPè®¡ç®—
        radius = 1
        n_points = 8 * radius
        
        # ä½¿ç”¨ç®€å•çš„çº¹ç†æ–¹å·®ä»£æ›¿å¤æ‚çš„LBPè®¡ç®—
        return np.var(gray)
    
    def _detect_faces(self, img):
        """æ£€æµ‹äººè„¸"""
        # ä½¿ç”¨OpenCVçš„äººè„¸æ£€æµ‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # å°è¯•åŠ è½½äººè„¸æ£€æµ‹å™¨
        face_cascade = cv2.CascadeClassifier()
        
        # ç®€åŒ–çš„é¢éƒ¨åŒºåŸŸæ£€æµ‹
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥ä½¿ç”¨çœŸæ­£çš„äººè„¸æ£€æµ‹
        return []
    
    def _analyze_skin_regions(self, img):
        """åˆ†æçš®è‚¤åŒºåŸŸ"""
        # ç®€åŒ–çš„çš®è‚¤é¢œè‰²æ£€æµ‹
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # å®šä¹‰çš®è‚¤é¢œè‰²èŒƒå›´ï¼ˆHSVç©ºé—´ï¼‰
        lower_skin = np.array([0, 20, 70], dtype=np.uint8)
        upper_skin = np.array([20, 255, 255], dtype=np.uint8)
        
        # åˆ›å»ºçš®è‚¤æ©ç 
        skin_mask = cv2.inRange(hsv, lower_skin, upper_skin)
        
        # æå–çš®è‚¤åŒºåŸŸ
        skin_pixels = img[skin_mask > 0]
        
        if len(skin_pixels) > 0:
            avg_skin_tone = np.mean(skin_pixels, axis=0)
        else:
            avg_skin_tone = [0, 0, 0]
        
        return {'average_skin_tone': avg_skin_tone.tolist()}
    
    def _analyze_hair_regions(self, img):
        """åˆ†æå¤´å‘åŒºåŸŸ"""
        # ç®€åŒ–çš„å¤´å‘é¢œè‰²æ£€æµ‹
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # å‡è®¾æš—è‰²åŒºåŸŸå¯èƒ½æ˜¯å¤´å‘
        hair_mask = gray < 80
        hair_pixels = img[hair_mask]
        
        if len(hair_pixels) > 0:
            avg_hair_color = np.mean(hair_pixels, axis=0)
        else:
            avg_hair_color = [0, 0, 0]
        
        return {'average_hair_color': avg_hair_color.tolist()}
    
    def _calculate_sharpness(self, img):
        """è®¡ç®—å›¾åƒæ¸…æ™°åº¦"""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­è®¡ç®—æ¸…æ™°åº¦
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        sharpness = np.var(laplacian)
        
        return sharpness
    
    def _save_analysis_results(self):
        """ä¿å­˜åˆ†æç»“æœ"""
        # è½¬æ¢ä¸ºå¯JSONåºåˆ—åŒ–çš„æ ¼å¼
        serializable_results = {}
        
        for category, features in self.analysis_results.items():
            serializable_results[category] = {}
            for feature_name, values in features.items():
                # å¤„ç†numpyæ•°ç»„å’Œæ ‡é‡
                if isinstance(values, list):
                    serializable_results[category][feature_name] = [
                        float(v) if isinstance(v, (np.floating, float)) else v 
                        for v in values
                    ]
                else:
                    serializable_results[category][feature_name] = values
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        output_file = os.path.join(self.reference_folder, 'ghibli_analysis_results.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    def generate_optimization_parameters(self):
        """ç”Ÿæˆä¼˜åŒ–å‚æ•°"""
        if not self.analysis_results:
            print("âŒ è¯·å…ˆè¿è¡Œcollect_ghibli_references()æ”¶é›†å‚è€ƒå›¾ç‰‡")
            return None
        
        print("ğŸ¯ ç”Ÿæˆå®«å´éªé£æ ¼ä¼˜åŒ–å‚æ•°...")
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆä¼˜åŒ–å‚æ•°
        optimization_params = {
            'color_optimization': self._generate_color_params(),
            'texture_optimization': self._generate_texture_params(),
            'character_optimization': self._generate_character_params(),
            'lighting_optimization': self._generate_lighting_params()
        }
        
        # ä¿å­˜ä¼˜åŒ–å‚æ•°
        params_file = os.path.join(self.reference_folder, 'optimization_parameters.json')
        with open(params_file, 'w', encoding='utf-8') as f:
            json.dump(optimization_params, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ä¼˜åŒ–å‚æ•°å·²ä¿å­˜åˆ°: {params_file}")
        return optimization_params
    
    def _generate_color_params(self):
        """ç”Ÿæˆè‰²å½©ä¼˜åŒ–å‚æ•°"""
        color_data = self.analysis_results.get('color_analysis', {})
        
        # è®¡ç®—å¹³å‡é¥±å’Œåº¦å’Œäº®åº¦
        avg_saturation = np.mean(color_data.get('saturation', [0.5]))
        avg_brightness = np.mean(color_data.get('brightness', [0.5]))
        
        return {
            'saturation_boost': max(1.0, 1.5 - avg_saturation / 128),
            'brightness_adjust': max(1.0, 1.3 - avg_brightness / 128),
            'contrast_enhance': 1.2
        }
    
    def _generate_texture_params(self):
        """ç”Ÿæˆçº¹ç†ä¼˜åŒ–å‚æ•°"""
        texture_data = self.analysis_results.get('texture_analysis', {})
        
        avg_gradient = np.mean(texture_data.get('gradient_strength', [10]))
        
        return {
            'smoothing_strength': min(15, max(5, avg_gradient / 5)),
            'edge_preservation': 0.8,
            'detail_enhancement': 1.1
        }
    
    def _generate_character_params(self):
        """ç”Ÿæˆäººç‰©ä¼˜åŒ–å‚æ•°"""
        character_data = self.analysis_results.get('character_analysis', {})
        
        avg_sharpness = np.mean(character_data.get('character_sharpness', [100]))
        
        return {
            'face_enhancement': True,
            'skin_smoothing': 0.7,
            'eye_enhancement': 1.3,
            'sharpness_boost': max(1.0, 200 / avg_sharpness)
        }
    
    def _generate_lighting_params(self):
        """ç”Ÿæˆå…‰å½±ä¼˜åŒ–å‚æ•°"""
        lighting_data = self.analysis_results.get('lighting_analysis', {})
        
        avg_contrast = np.mean(lighting_data.get('contrast', [40]))
        
        return {
            'soft_lighting': True,
            'shadow_reduction': 0.3,
            'highlight_enhancement': 1.1,
            'contrast_adjust': max(1.0, 60 / avg_contrast)
        }

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¨ å®«å´éªé£æ ¼ä¼˜åŒ–å™¨")
    print("=" * 60)
    
    optimizer = GhibliStyleOptimizer()
    
    # ç¡®ä¿tempç›®å½•å­˜åœ¨
    os.makedirs('temp', exist_ok=True)
    
    # æ”¶é›†å’Œåˆ†æå‚è€ƒå›¾ç‰‡
    if optimizer.collect_ghibli_references():
        # ç”Ÿæˆä¼˜åŒ–å‚æ•°
        optimizer.generate_optimization_parameters()
        
        print("\nğŸ“‹ ä½¿ç”¨è¯´æ˜:")
        print("1. å°†æ›´å¤šçš„å®«å´éªé£æ ¼å›¾ç‰‡æ”¾å…¥tempæ–‡ä»¶å¤¹")
        print("2. é‡æ–°è¿è¡Œæ­¤è„šæœ¬æ¥æ›´æ–°åˆ†æç»“æœ")
        print("3. ä½¿ç”¨ç”Ÿæˆçš„ä¼˜åŒ–å‚æ•°æ”¹è¿›é£æ ¼è½¬æ¢æ¨¡å‹")
    
    print("\n" + "=" * 60)
    print("âœ… ä¼˜åŒ–å®Œæˆ")
    print("=" * 60)

if __name__ == '__main__':
    main()