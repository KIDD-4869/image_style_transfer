#!/usr/bin/env python3
"""
æ”¹è¿›çš„å®«å´éªé£æ ¼è½¬æ¢æ¨¡å‹ - åŸºäºtempæ–‡ä»¶å¤¹ä¸­çš„å‚è€ƒå›¾ç‰‡å­¦ä¹ 
"""

import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
import io
import base64
from flask import Flask, render_template, request, jsonify
import os
import json
import glob

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'static/uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# åˆ›å»ºä¸Šä¼ ç›®å½•
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

class ImprovedGhibliStyleTransfer:
    """æ”¹è¿›çš„å®«å´éªé£æ ¼è½¬æ¢æ¨¡å‹ - åŸºäºå‚è€ƒå›¾ç‰‡å­¦ä¹ """
    
    def __init__(self):
        self.temp_folder = 'temp'
        self.ghibli_features = self._load_ghibli_features()
        self.ghibli_params = self._load_processing_params()
        
    def _load_ghibli_features(self):
        """åŠ è½½å®«å´éªé£æ ¼ç‰¹å¾"""
        features_file = os.path.join(self.temp_folder, 'ghibli_style_features.json')
        if os.path.exists(features_file):
            with open(features_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            # é»˜è®¤å®«å´éªé£æ ¼ç‰¹å¾
            return {
                "color_palette": {
                    "sky_blue": [135, 206, 235],
                    "grass_green": [144, 238, 144],
                    "character_skin": [255, 218, 185],
                    "hair_brown": [165, 42, 42],
                    "dress_pink": [255, 192, 203],
                },
                "lighting_characteristics": {
                    "soft_shadows": True,
                    "warm_tones": True,
                    "dreamy_atmosphere": True
                }
            }
    
    def _load_processing_params(self):
        """åŠ è½½å¤„ç†å‚æ•°"""
        params_file = os.path.join(self.temp_folder, 'ghibli_processing_params.json')
        if os.path.exists(params_file):
            with open(params_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            # é»˜è®¤å¤„ç†å‚æ•°
            return {
                "bilateral_filter": {"d": 9, "sigmaColor": 75, "sigmaSpace": 75},
                "edge_preservation": {"strength": 0.8},
                "color_enhancement": {
                    "saturation_boost": 1.3,
                    "brightness_adjust": 1.1,
                    "contrast_enhance": 1.2
                }
            }
    
    def _analyze_reference_images(self):
        """åˆ†ætempæ–‡ä»¶å¤¹ä¸­çš„å‚è€ƒå›¾ç‰‡"""
        reference_images = []
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']
        
        for ext in image_extensions:
            pattern = os.path.join(self.temp_folder, ext)
            reference_images.extend(glob.glob(pattern))
        
        if not reference_images:
            print("âš ï¸  tempæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°å‚è€ƒå›¾ç‰‡ï¼Œä½¿ç”¨é»˜è®¤å®«å´éªé£æ ¼")
            return None
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(reference_images)} å¼ å‚è€ƒå›¾ç‰‡")
        
        # åˆ†æå‚è€ƒå›¾ç‰‡çš„è‰²å½©ç‰¹å¾
        color_features = self._extract_color_features(reference_images)
        
        return color_features
    
    def _extract_color_features(self, image_paths):
        """ä»å‚è€ƒå›¾ç‰‡ä¸­æå–è‰²å½©ç‰¹å¾"""
        color_features = {
            'hue_distribution': [],
            'saturation_levels': [],
            'brightness_levels': [],
            'dominant_colors': []
        }
        
        for img_path in image_paths:
            try:
                img = cv2.imread(img_path)
                if img is None:
                    continue
                    
                # è½¬æ¢ä¸ºHSVè‰²å½©ç©ºé—´
                hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
                
                # åˆ†æè‰²è°ƒåˆ†å¸ƒ
                hue_hist = cv2.calcHist([hsv], [0], None, [180], [0, 180])
                color_features['hue_distribution'].append(hue_hist)
                
                # åˆ†æé¥±å’Œåº¦å’Œäº®åº¦
                saturation = np.mean(hsv[:,:,1])
                brightness = np.mean(hsv[:,:,2])
                color_features['saturation_levels'].append(saturation)
                color_features['brightness_levels'].append(brightness)
                
                # æå–ä¸»è‰²è°ƒ
                pixels = img.reshape(-1, 3)
                dominant_color = np.mean(pixels, axis=0)
                color_features['dominant_colors'].append(dominant_color)
                
            except Exception as e:
                print(f"âŒ åˆ†æå›¾ç‰‡ {img_path} æ—¶å‡ºé”™: {e}")
        
        return color_features
    
    def apply_ghibli_style(self, image):
        """åº”ç”¨æ”¹è¿›çš„å®«å´éªé£æ ¼"""
        
        # åˆ†æå‚è€ƒå›¾ç‰‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        reference_features = self._analyze_reference_images()
        
        # å°†PILå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
        img_np = np.array(image)
        
        # è½¬æ¢ä¸ºBGRæ ¼å¼
        if len(img_np.shape) == 3 and img_np.shape[2] == 3:
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
        else:
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)
        
        # 1. é«˜è´¨é‡é¢„å¤„ç†
        processed = self._high_quality_preprocess(img_bgr)
        
        # 2. åŸºäºå‚è€ƒå›¾ç‰‡çš„è‰²å½©è°ƒæ•´
        if reference_features:
            processed = self._adjust_colors_based_on_reference(processed, reference_features)
        
        # 3. æ™ºèƒ½è¾¹ç¼˜ä¿ç•™å¹³æ»‘
        smoothed = self._smart_edge_preserving_smooth(processed)
        
        # 4. å®«å´éªé£æ ¼è‰²å½©æ˜ å°„
        ghibli_colors = self._ghibli_style_color_mapping(smoothed)
        
        # 5. ç»†èŠ‚å¢å¼ºå’Œæ¢å¤
        detailed = self._enhance_and_preserve_details(ghibli_colors, processed)
        
        # 6. æ¢¦å¹»å…‰å½±æ•ˆæœ
        final = self._apply_dreamy_lighting(detailed)
        
        # è½¬æ¢å›RGBæ ¼å¼
        result_rgb = cv2.cvtColor(final, cv2.COLOR_BGR2RGB)
        
        return result_rgb
    
    def _high_quality_preprocess(self, img):
        """é«˜è´¨é‡é¢„å¤„ç†"""
        h, w = img.shape[:2]
        
        # ä¿æŒåŸå§‹åˆ†è¾¨ç‡ï¼Œä»…åœ¨è¿‡å¤§æ—¶è°ƒæ•´
        max_size = 2000
        if max(h, w) > max_size:
            scale = max_size / max(h, w)
            new_w, new_h = int(w * scale), int(h * scale)
            img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
        
        return img
    
    def _adjust_colors_based_on_reference(self, img, reference_features):
        """åŸºäºå‚è€ƒå›¾ç‰‡è°ƒæ•´è‰²å½©"""
        # è½¬æ¢ä¸ºLABè‰²å½©ç©ºé—´è¿›è¡Œæ›´ç²¾ç¡®çš„è‰²å½©è°ƒæ•´
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        
        # è°ƒæ•´äº®åº¦å’Œå¯¹æ¯”åº¦
        l, a, b = cv2.split(lab)
        
        # åŸºäºå‚è€ƒå›¾ç‰‡çš„äº®åº¦ç‰¹å¾è°ƒæ•´
        if reference_features['brightness_levels']:
            target_brightness = np.mean(reference_features['brightness_levels'])
            current_brightness = np.mean(l)
            brightness_ratio = target_brightness / current_brightness if current_brightness > 0 else 1.0
            l = cv2.multiply(l, brightness_ratio)
        
        # åˆå¹¶é€šé“
        lab_adjusted = cv2.merge([l, a, b])
        
        # è½¬æ¢å›BGR
        result = cv2.cvtColor(lab_adjusted, cv2.COLOR_LAB2BGR)
        
        return result
    
    def _smart_edge_preserving_smooth(self, img):
        """æ™ºèƒ½è¾¹ç¼˜ä¿ç•™å¹³æ»‘"""
        params = self.ghibli_params['bilateral_filter']
        
        # åŒè¾¹æ»¤æ³¢ï¼Œä¿ç•™è¾¹ç¼˜
        smoothed = cv2.bilateralFilter(
            img, 
            params['d'], 
            params['sigmaColor'], 
            params['sigmaSpace']
        )
        
        return smoothed
    
    def _ghibli_style_color_mapping(self, img):
        """å®«å´éªé£æ ¼è‰²å½©æ˜ å°„"""
        # è½¬æ¢ä¸ºHSVè‰²å½©ç©ºé—´
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # å¢å¼ºé¥±å’Œåº¦ï¼ˆå®«å´éªé£æ ¼é€šå¸¸è‰²å½©é²œè‰³ï¼‰
        h, s, v = cv2.split(hsv)
        
        params = self.ghibli_params['color_enhancement']
        s = cv2.multiply(s, params['saturation_boost'])
        v = cv2.multiply(v, params['brightness_adjust'])
        
        # é™åˆ¶å€¼èŒƒå›´
        s = np.clip(s, 0, 255)
        v = np.clip(v, 0, 255)
        
        # åˆå¹¶é€šé“
        hsv_enhanced = cv2.merge([h, s, v])
        
        # è½¬æ¢å›BGR
        result = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)
        
        return result
    
    def _enhance_and_preserve_details(self, img, original):
        """å¢å¼ºå’Œä¿ç•™ç»†èŠ‚"""
        # æå–åŸå›¾çš„é«˜é¢‘ç»†èŠ‚
        original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # è®¡ç®—ç»†èŠ‚å·®å¼‚
        detail_diff = cv2.subtract(original_gray, img_gray)
        
        # å¢å¼ºç»†èŠ‚
        enhanced_detail = cv2.multiply(detail_diff, 0.3)
        
        # å°†ç»†èŠ‚æ·»åŠ å›ç»“æœ
        result_gray = cv2.add(img_gray, enhanced_detail)
        
        # å°†ç°åº¦ç»†èŠ‚åº”ç”¨åˆ°å½©è‰²å›¾åƒ
        result = img.copy()
        for i in range(3):
            result[:,:,i] = cv2.addWeighted(
                result[:,:,i], 0.7, 
                result_gray, 0.3, 0
            )
        
        return result
    
    def _apply_dreamy_lighting(self, img):
        """åº”ç”¨æ¢¦å¹»å…‰å½±æ•ˆæœ"""
        # åˆ›å»ºæŸ”å’Œçš„å…‰ç…§æ•ˆæœ
        h, w = img.shape[:2]
        
        # åˆ›å»ºä¸­å¿ƒäº®å››å‘¨æš—çš„å…‰ç…§é®ç½©
        y, x = np.ogrid[:h, :w]
        center_y, center_x = h / 2, w / 2
        
        # è®¡ç®—è·ç¦»ä¸­å¿ƒçš„è·ç¦»
        distance = np.sqrt((x - center_x)**2 + (y - center_y)**2)
        max_distance = np.sqrt(center_x**2 + center_y**2)
        
        # åˆ›å»ºå…‰ç…§é®ç½©ï¼ˆä¸­å¿ƒäº®ï¼Œå››å‘¨æš—ï¼‰
        light_mask = 1.0 - (distance / max_distance) * 0.3
        light_mask = np.clip(light_mask, 0.7, 1.0)
        
        # åº”ç”¨å…‰ç…§æ•ˆæœ
        result = img.astype(np.float32) * light_mask[:,:,np.newaxis]
        result = np.clip(result, 0, 255).astype(np.uint8)
        
        return result

# åˆ›å»ºæ”¹è¿›çš„æ¨¡å‹å®ä¾‹
improved_model = ImprovedGhibliStyleTransfer()

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ å’Œé£æ ¼è½¬æ¢"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})
        
        # è¯»å–å›¾ç‰‡
        image = Image.open(file.stream)
        
        # åº”ç”¨æ”¹è¿›çš„å®«å´éªé£æ ¼
        result_image = improved_model.apply_ghibli_style(image)
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        result_pil = Image.fromarray(result_image)
        
        # è½¬æ¢ä¸ºbase64
        buffered = io.BytesIO()
        result_pil.save(buffered, format="JPEG", quality=95)
        img_str = base64.b64encode(buffered.getvalue()).decode()
        
        return jsonify({
            'success': True,
            'image': f"data:image/jpeg;base64,{img_str}"
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5003)